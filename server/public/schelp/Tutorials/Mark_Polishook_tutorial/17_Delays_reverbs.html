<!doctype html><html lang='en'><head><title>17_Delays_reverbs | SuperCollider 3.11.2 Help</title>
<link rel='stylesheet' href='./../../scdoc.css' type='text/css' />
<link rel='stylesheet' href='./../../codemirror.css' type='text/css' />
<link rel='stylesheet' href='./../../editor.css' type='text/css' />
<link rel='stylesheet' href='./../../frontend.css' type='text/css' />
<link rel='stylesheet' href='./../../custom.css' type='text/css' />
<meta name='viewport' content='width=device-width, initial-scale=1'>
<meta http-equiv='Content-Type' content='text/html; charset=UTF-8' />
<script src='./../../lib/jquery.min.js'></script>
<script src='./../../lib/codemirror-5.39.2.min.js' type='text/javascript'></script>
<script src='./../../lib/codemirror-addon-simple-5.39.2.min.js' type='text/javascript'></script>
<script>
var helpRoot = './../..';
var scdoc_title = '17_Delays_reverbs';
var scdoc_sc_version = '3.11.2';
</script>
<script src='./../../scdoc.js' type='text/javascript'></script>
<script src='./../../docmap.js' type='text/javascript'></script>
<script src='qrc:///qtwebchannel/qwebchannel.js' type='text/javascript'></script>
</head>
<body onload='fixTOC()'>
<div id='toc'>
<div id='toctitle'>17_Delays_reverbs:</div>
<span class='toc_search'>Filter: <input id='toc_search'></span><ul class='toc'><li class='toc1'><a href='#Time-based%20filters'>Time-based filters</a></li>
<ul class='toc'></ul><li class='toc1'><a href='#Feedback%20filters'>Feedback filters</a></li>
<ul class='toc'></ul><li class='toc1'><a href='#Reverberation'>Reverberation</a></li>
<ul class='toc'></ul><li class='toc1'><a href='#Components'>Components</a></li>
<ul class='toc'></ul><li class='toc1'><a href='#Why%20SuperCollider%202.0?'>Why SuperCollider 2.0?</a></li>
<ul class='toc'></ul></ul></div><div id='menubar'></div>
<div class='contents'>
<div class='header'>
<div id='label'>
<span id='folder'>Tutorials/Mark_Polishook_tutorial</span>
 | <span id='categories'><a href='./../../Browse.html#Tutorials'>Tutorials</a>&#8201;&gt;&#8201;<a href='./../../Browse.html#Tutorials>Mark_Polishook_tutorial'>Mark_Polishook_tutorial</a></span>
</div><h1>17_Delays_reverbs</h1>
<div id='summary'>Mark Polishook tutorial</div>
</div>
<div class='subheader'>
<div id='related'>See also: <a href="./../../Tutorials/Mark_Polishook_tutorial/00_Introductory_tutorial.html">00_Introductory tutorial</a></div>
</div>
<h2><a class='anchor' name='Time-based%20filters'>Time-based filters</a></h2>

<p>The Delay, Comb, and Allpass family of ugens create time-based effects to give a sense of location and space.
<p>////////////////////////////////////////////////////////////////////////////////////////////////////<textarea class='editor'>// 2 synthdefs - the 1st to make grains and the 2nd to delay them

// the synthdef that makes the grains is on the left channel
// the synthdef that delays the grains is on the right channel
(
SynthDef("someGrains", { arg centerFreq = 777, freqDev = 200, grainFreq = 2;
    var gate;
    gate = Impulse.kr(grainFreq);
    Out.ar(
        0,
        SinOsc.ar(
            LFNoise0.kr(4, freqDev, centerFreq),
            0,
            EnvGen.kr(Env.sine(0.1), gate, 0.1)
        )
    )
}).add;

SynthDef("aDelay", { arg delay = 0.25;
    Out.ar(
        1,
        DelayN.ar(
            In.ar(0, 1),
            delay,
            delay
        )
    )
}).add;
)

////////////////////////////////////////////////
// test the grains ... and then turn them off
// ... they're all on the left channel ... good!
Synth("someGrains");
////////////////////////////////////////////////

// make 2 groups, the 1st for sources and the 2nd for effects
(
~source = Group.head(s);
~effects = Group.tail(s);
)

// place grains into the delay ... source is on the left and delayed source is on the right
(
Synth.head(~source, "someGrains");
Synth.head(~effects, "aDelay");
)</textarea>
<h2><a class='anchor' name='Feedback%20filters'>Feedback filters</a></h2>

<p>Comb and Allpass filters are examples of ugens that feed some of their output back into their input. Allpass filters change the phase of signals passed through them. For this reason, they're useful even though don't seem to differ much from comb filters.<textarea class='editor'>/////////////////////////////////////////////////////////////////////////////////////////
// TURN ON THE INTERNAL SERVER!!
// first a comb filter and then an allpass with (with the same parameters) - compare them
/////////////////////////////////////////////////////////////////////////////////////////

// comb example
(
{
    CombN.ar(
        SinOsc.ar(500.rrand(1000), 0, 0.2) * Line.kr(1, 0, 0.1),
        0.3,
        0.25,
        6
    )
}.scope;
)

// allpass example - not much difference from the comb example
(
{
    AllpassN.ar(
        SinOsc.ar(500.rrand(1000), 0, 0.2) * Line.kr(1, 0, 0.1),
        0.3,
        0.25,
        6
    )
}.scope;
)</textarea>
<textarea class='editor'>/////////////////////////////////////////////////////////////////////////////////////////
//
// first a comb example and then an allpass
// both examples have the same parameters
// the 2 examples have relatively short delay times ... 0.1 seconds
//
/////////////////////////////////////////////////////////////////////////////////////////


// comb
(
{
    CombN.ar(
        SinOsc.ar(500.rrand(1000), 0, 0.2) * Line.kr(1, 0, 0.1),
        0.1,
        0.025,
        6
    )
}.scope;
)

// allpass ... what's the difference between this example and the comb filter?
(
{
    AllpassN.ar(
        SinOsc.ar(500.rrand(1000), 0, 0.2) * Line.kr(1, 0, 0.1),
        0.1,
        0.025,
        6
    )
}.scope
)</textarea>
<h2><a class='anchor' name='Reverberation'>Reverberation</a></h2>

<p>The next example is by James McCartney. It comes from the <em>Why Supercollider 2.0?</em> document that was part of the SuperCollider2 distribution.
<p>The example is more or less a Schroeder reverb - a signal passed through a parallel bank of comb filters which then pass through a series of allpass filters.<textarea class='editor'>(
{
var s, z, y;
    // 10 voices of a random sine percussion sound :
s = Mix.ar(Array.fill(10, { Resonz.ar(Dust.ar(0.2, 50), 200 + 3000.0.rand, 0.003)}) );
    // reverb predelay time :
z = DelayN.ar(s, 0.048);
    // 7 length modulated comb delays in parallel :
y = Mix.ar(Array.fill(7,{ CombL.ar(z, 0.1, LFNoise1.kr(0.1.rand, 0.04, 0.05), 15) }));
    // two parallel chains of 4 allpass delays (8 total) :
4.do({ y = AllpassN.ar(y, 0.050, [0.050.rand, 0.050.rand], 1) });
    // add original sound to reverb and play it :
s+(0.2*y)
}.scope
)</textarea>
<h2><a class='anchor' name='Components'>Components</a></h2>

<p>The following shows one way to divide the JMC example into components.<textarea class='editor'>(
SynthDef("filteredDust", {
    Out.ar(
        2,
        Mix.arFill(10, { Resonz.ar(Dust.ar(0.2, 50), Rand(200, 3200), 0.003) })
    )
}).add;

SynthDef("preDelay", {
    ReplaceOut.ar(
        4,
        DelayN.ar(In.ar(2, 1), 0.048, 0.048)
    )
}).add;

SynthDef("combs", {
    ReplaceOut.ar(
        6,
        Mix.arFill(7, { CombL.ar(In.ar(4, 1), 0.1, LFNoise1.kr(Rand(0, 0.1), 0.04, 0.05), 15) })
    )
}).add;

SynthDef("allpass", { arg gain = 0.2;
    var source;
    source = In.ar(6, 1);
    4.do({ source = AllpassN.ar(source, 0.050, [Rand(0, 0.05), Rand(0, 0.05)], 1) });
    ReplaceOut.ar(
        8,
        source * gain
    )
}).add;

SynthDef("theMixer", { arg gain = 1;
    ReplaceOut.ar(
        0,
        Mix.ar([In.ar(2, 1), In.ar(8, 2)]) * gain
    )
}).add;
)

// as each line is executed, it becomes the tail node. the result is that
// "filteredDust" is the first node and  "theMixer" is the last node ...
// ... exactly what we need
(
Synth.tail(s, "filteredDust");
Synth.tail(s, "preDelay");
Synth.tail(s, "combs");
Synth.tail(s, "allpass");
Synth.tail(s, "theMixer");
)

(
s.queryAllNodes;
)</textarea>

<p>////////////////////////////////////////////////////////////////////////////////////////////////////
<p>Or, use groups to control the order of execution.<textarea class='editor'>(
~source = Group.tail(s);
~proc1 = Group.tail(s);
~proc2 = Group.tail(s);
~proc3 = Group.tail(s);
~final = Group.tail(s);
)

// the nodes, below, are assigned to the groups, as ordered above,
(
Synth.head(~final, "theMixer");
Synth.head(~proc3, "allpass");
Synth.head(~proc2, "combs");
Synth.head(~proc1, "preDelay");
Synth.head(~source, "filteredDust");
)

(
s.queryAllNodes;
)</textarea>

<p>////////////////////////////////////////////////////////////////////////////////////////////////////
<p>For context, here, below, is the complete text of the <strong>01 Why SuperCollider</strong> document (by James McCartney) from the SuperCollider 2 distribution.<h2><a class='anchor' name='Why%20SuperCollider%202.0?'>Why SuperCollider 2.0?</a></h2>

<p>SuperCollider version 2.0 is a new programming language. <strong>Why invent a new language and not use an existing language?</strong> Computer music composition is a specification problem. Both sound synthesis and the composition of sounds are complex problems and demand a language which is highly expressive in order to deal with that complexity. Real time signal processing is a problem demanding an efficient implementation with bounded time operations. There was no language combining the features I wanted and needed for doing digital music synthesis. The SuperCollider language is most like Smalltalk. Everything is an object. It has class objects, methods, dynamic typing, full closures, default arguments, variable length argument lists, multiple assignment, etc. The implementation provides fast, constant time method lookup, real time garbage collection, and stack allocation of most function contexts while maintaining full closure semantics. The SuperCollider virtual machine is designed so that it can be run at interrupt level. There was no other language readily available that was high level, real time and capable of running at interrupt level.
<p>SuperCollider version 1.0 was completely rewritten to make it both more expressive and more efficient. This required rethinking the implementation in light of the experience of the first version. It is my opinion that the new version has benefitted significantly from this rethink. It is not simply version 1.0 with more features.
<p><strong>Why use a text based language rather than a graphical language?</strong>There are at least two answers to this. <strong>Dynamism</strong> : Most graphical synthesis environments use statically allocated unit generators. In SuperCollider, the user can create structures which spawn events dynamically and in a nested fashion. Patches can be built dynamically and parameterized not just by floating point numbers from a static score, but by other graphs of unit generators as well. Or you can construct patches algorithmically on the fly. This kind of fluidity is not possible in a language with statically allocated unit generators. <strong>Brevity</strong> : In SuperCollider, symmetries in a patch can be exploited by either multichannel expansion or programmatic patch building. For example, the following short program generates a patch of 49 unit generators. In a graphical program this might require a significant amount of time and space to wire up. Another advantage is that the size of the patch below can be easily expanded or contracted just by changing a few constants.<textarea class='editor'>(
{
    // 10 voices of a random sine percussion sound :
s = Mix.ar(Array.fill(10, { Resonz.ar(Dust.ar(0.2, 50), 200 + 3000.0.rand, 0.003)}) );
    // reverb predelay time :
z = DelayN.ar(s, 0.048);
    // 7 length modulated comb delays in parallel :
y = Mix.ar(Array.fill(7,{ CombL.ar(z, 0.1, LFNoise1.kr(0.1.rand, 0.04, 0.05), 15) }));
    // two parallel chains of 4 allpass delays (8 total) :
4.do({ y = AllpassN.ar(y, 0.050, [0.050.rand, 0.050.rand], 1) });
    // add original sound to reverb and play it :
s+(0.2*y)
}.play )</textarea>

<p>Graphical synthesis environments are becoming a dime a dozen. It seems like a new one is announced every month. None of them have the dynamic flexibility of SuperCollider's complete programming environment. Look through the SuperCollider help files and examples and see for yourself.
<p>////////////////////////////////////////////////////////////////////////////////////////////////////
<p>go to <a href="./../../Tutorials/Mark_Polishook_tutorial/18_Frequency_modulation.html">18_Frequency_modulation</a><div class='doclink'>helpfile source: <a href='file:///usr/share/SuperCollider/HelpSource/Tutorials/Mark_Polishook_tutorial/17_Delays_reverbs.schelp'>/usr/share/SuperCollider/HelpSource/Tutorials/Mark_Polishook_tutorial/17_Delays_reverbs.schelp</a><br>link::Tutorials/Mark_Polishook_tutorial/17_Delays_reverbs::<br></div></div><script src='./../../editor.js' type='text/javascript'></script>
</body></html>